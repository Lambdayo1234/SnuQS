#include "simulator_cuda.h"

#include <cmath>
#include <cstdlib>

#include <thrust/complex.h>
#include <thrust/host_vector.h>
#include <thrust/device_vector.h>


#define CHECK_CUDA(e)          \
  do {                         \
    if ((e) != cudaSuccess) {  \
      std::cout                \
        << "CUDA ERROR!["      \
        << __FILE__            \
        << ":"                 \
        << __LINE__            \
        << "]\n";              \
      std::exit(EXIT_FAILURE); \
    }                          \
  } while (0)

using namespace std::complex_literals;
namespace snuqs {

SimulatorCUDA::SimulatorCUDA() {
}

SimulatorCUDA::~SimulatorCUDA() {
}

__global__ static void kernel_init(
    Qreg::device_amp_t *buf,
    int num_qubits
    )
{
  uint64_t i = blockIdx.x * blockDim.x + threadIdx.x;
  buf[i] = 0.;
  if (i == 0)
    buf[i] = 1.;
}

__global__ static void kernel_ugate(
    Qreg::device_amp_t *buf,
    int num_qubits, 
    int *qubits,
    int num_targets,
    double *params,
    int num_params) {
  uint64_t target = qubits[0];
  uint64_t st = (1ul << target);
  uint64_t i = blockIdx.x * blockDim.x + threadIdx.x;
	uint64_t j = ((i >> target) << (target+1)) + (i & (st-1));

  double theta = params[0];
  double phi = params[1];
  double lambda = params[2];
  Qreg::device_amp_t _1i{0, 1};
  Qreg::device_amp_t a00 = cos(theta/2);
  Qreg::device_amp_t a01 = -exp(_1i*lambda) * sin(theta/2);
  Qreg::device_amp_t a10 = exp(_1i*phi) * sin(theta/2);
  Qreg::device_amp_t a11 = exp(_1i*(phi+lambda)) * cos(theta/2);

  Qreg::device_amp_t v0 = a00 * buf[j] + a01 * buf[j+st];
  Qreg::device_amp_t v1 = a10 * buf[j] + a11 * buf[j+st];
  buf[j] = v0;
  buf[j+st] = v1;
}

__global__ static void kernel_cxgate(
    Qreg::device_amp_t *buf,
    int num_qubits,
    int *qubits,
    int num_targets) {
  uint64_t ctrl = qubits[0];
  uint64_t target = qubits[1];
  uint64_t t0 = qubits[0];
  uint64_t t1 = qubits[1];

  if (ctrl > target) {
    uint64_t tmp = t0;
    t0 = t1;
    t1 = tmp;
  }

  uint64_t st0 = (1ul << t0);
  uint64_t st1 = (1ul << t1);
  uint64_t cst = (1ul << ctrl);
  uint64_t tst = (1ul << target);

  uint64_t i = blockIdx.x * blockDim.x + threadIdx.x;
  uint64_t j = ((i >> t0) << (t0+1)) + (i & (st0-1));
  uint64_t k = ((j >> t1) << (t1+1)) + (j & (st1-1));

  Qreg::device_amp_t tmp = buf[k+cst+tst];
  buf[k+cst+tst] = buf[k+cst];
  buf[k+cst] = tmp;
}

void SimulatorCUDA::init(Qop *qop, Qreg &qreg, Creg &creg) {
  Qreg::device_amp_t *buf = qreg.get_device_buf(0);
  int num_qubits = qreg.get_num_qubits();

  uint64_t num_amps = (1ul << num_qubits);
  dim3 blockDim(128);
  dim3 gridDim(((num_amps) + blockDim.x - 1) / blockDim.x);
  kernel_init<<<gridDim, blockDim>>>(buf, num_qubits);
  CHECK_CUDA(cudaGetLastError());
}

void SimulatorCUDA::fini(Qop *qop, Qreg &qreg, Creg &creg) {
  Qreg::amp_t *host_buf = qreg.get_buf();
  Qreg::device_amp_t *device_buf = qreg.get_device_buf(0);
  int num_qubits = qreg.get_num_qubits();

  uint64_t num_amps = (1ul << num_qubits);
  CHECK_CUDA(cudaMemcpy(host_buf, device_buf, sizeof(Qreg::amp_t) * num_amps, cudaMemcpyDeviceToHost));
}

void SimulatorCUDA::cond(Qop *qop, Qreg &qreg, Creg &creg) {
  int val = 0;
  int k = 0;
  for (int i = qop->get_base(); i < qop->get_limit(); ++i) {
    if (creg.get_buf()[i] == 1) {
      val += (1ul << k);
    }
    k += 1;
  }
  if (val == qop->get_value()) {
    run_op(qop->get_op(), qreg, creg);
  }
}

void SimulatorCUDA::measure(Qop *qop, Qreg &qreg, Creg &creg) {
  Qreg::amp_t *buf = qreg.get_buf();
  int num_qubits = qreg.get_num_qubits();
  const std::vector<int> &qubits = qop->get_qubits();
  int *creg_buf = creg.get_buf();
  int num_bits = creg.get_num_bits();
  const std::vector<int> &bits = qop->get_bits();

  uint64_t target = qubits[0];
  uint64_t tbit = bits[0];
  uint64_t st = (1ul << target);

  double threshold = (double)std::rand() / RAND_MAX;
  double prob0 = 0.;

  uint64_t num_amps = (1ul << num_qubits);

#pragma omp parallel for collapse(2) reduction(+:prob0)
  for (uint64_t i = 0; i < num_amps; i += 2*st) {
    for (uint64_t _j = 0; _j < st; ++_j) {
      uint64_t j = i + _j;
      prob0 += std::abs(buf[j]) * std::abs(buf[j]);
    }
  }


  int collapse_to_zero = false;
  if (threshold <= prob0) {
    collapse_to_zero = true;
    creg_buf[tbit] = 0;
  } else {
    collapse_to_zero = false;
    creg_buf[tbit] = 1;
  }


#pragma omp parallel for collapse(2)
  for (uint64_t i = 0; i < num_amps; i += 2*st) {
    for (uint64_t _j = 0; _j < st; ++_j) {
      uint64_t j = i + _j;
      if (collapse_to_zero) {
        buf[j] = buf[j] / std::sqrt(prob0);
        buf[j+st] = 0;
      } else {
        buf[j] = 0;
        buf[j+st] = buf[j+st] / std::sqrt(1-prob0);
      }
    }
  }
}

void SimulatorCUDA::reset(Qop *qop, Qreg &qreg, Creg &creg) {
  Qreg::amp_t *buf = qreg.get_buf();
  int num_qubits = qreg.get_num_qubits();
  const std::vector<int> &qubits = qop->get_qubits();


  uint64_t target = qubits[0];
  uint64_t st = (1ul << target);
  uint64_t num_amps = (1ul << num_qubits);
  double prob0 = 0.;

#pragma omp parallel for collapse(2) reduction(+:prob0)
  for (uint64_t i = 0; i < num_amps; i += 2*st) {
    for (uint64_t _j = 0; _j < st; ++_j) {
      uint64_t j = i + _j;
      prob0 += std::abs(buf[j]) * std::abs(buf[j]);
    }
  }

#pragma omp parallel for collapse(2)
  for (uint64_t i = 0; i < num_amps; i += 2*st) {
    for (uint64_t _j = 0; _j < st; ++_j) {
      uint64_t j = i + _j;
      buf[j] = buf[j] / std::sqrt(prob0);
      buf[j+st] = 0;
    }
  }
}

void SimulatorCUDA::barrier(Qop *qop, Qreg &qreg, Creg &creg) {
  /* Do nothing */
}

static void ugate(
    Qreg::device_amp_t *buf,
    int num_qubits,
    const std::vector<int> &qubits,
    const std::vector<double> &params) {

  uint64_t num_amps = (1ul << num_qubits);
  thrust::device_vector<int> d_qubits = qubits;
  thrust::device_vector<double> d_params = params;
  dim3 blockDim(128);
  dim3 gridDim(((num_amps / 2) + blockDim.x - 1) / blockDim.x);
  kernel_ugate<<<gridDim, blockDim>>>(buf, num_qubits,
      thrust::raw_pointer_cast(d_qubits.data()),
      d_qubits.size(),
      thrust::raw_pointer_cast(d_params.data()),
      d_params.size()
      );
  CHECK_CUDA(cudaGetLastError());
}

static void cxgate(
    Qreg::device_amp_t *buf,
    int num_qubits,
    const std::vector<int> &qubits) {
  uint64_t num_amps = (1ul << num_qubits);
  thrust::device_vector<int> d_qubits = qubits;
  dim3 blockDim(128);
  dim3 gridDim(((num_amps / 4) + blockDim.x - 1) / blockDim.x);
  kernel_cxgate<<<gridDim, blockDim>>>(buf, num_qubits,
      thrust::raw_pointer_cast(d_qubits.data()),
      d_qubits.size()
      );
  CHECK_CUDA(cudaGetLastError());

}

void SimulatorCUDA::run_op(Qop *qop, Qreg &qreg, Creg &creg) {
  switch (qop->get_type()) {
    case QopType::Init: init(qop, qreg, creg); break;
    case QopType::Fini: fini(qop, qreg, creg); break;
    case QopType::Cond: cond(qop, qreg, creg); break;
    case QopType::Measure: measure(qop, qreg, creg); break;
    case QopType::Reset: reset(qop, qreg, creg); break;
    case QopType::Barrier: barrier(qop, qreg, creg);
    case QopType::UGate:
      ugate(
          qreg.get_device_buf(0), qreg.get_num_qubits(), qop->get_qubits(), qop->get_params()
          );
      break;
    case QopType::CXGate:
      cxgate(
          qreg.get_device_buf(0), qreg.get_num_qubits(), qop->get_qubits()
          );
      break;
  }
}

void SimulatorCUDA::run(std::vector<Qop*> &circ, Qreg &qreg, Creg &creg) {
  std::cout << "[SnuQS] Running CUDA Simulator...\n";

  uint64_t num_amps = (1ul << qreg.get_num_qubits());
  Qreg::device_amp_t *device_buf;
  CHECK_CUDA(cudaMalloc(&device_buf, sizeof(Qreg::device_amp_t) * num_amps));
  qreg.set_device_buf(device_buf, 0);

  for (auto qop : circ) {
    run_op(qop, qreg, creg);
  }

  qreg.set_device_buf(nullptr, 0);
  CHECK_CUDA(cudaFree(device_buf));
}

} // namespace snuqs
